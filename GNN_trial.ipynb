{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdkit in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (2024.9.6)\n",
      "Requirement already satisfied: numpy in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from rdkit) (1.26.4)\n",
      "Requirement already satisfied: Pillow in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from rdkit) (11.1.0)\n",
      "Requirement already satisfied: torch in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from torch) (68.2.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: torch_geometric in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (2.6.1)\n",
      "Requirement already satisfied: aiohttp in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from torch_geometric) (3.9.3)\n",
      "Requirement already satisfied: fsspec in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from torch_geometric) (2025.3.0)\n",
      "Requirement already satisfied: jinja2 in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from torch_geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from torch_geometric) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from torch_geometric) (5.9.0)\n",
      "Requirement already satisfied: pyparsing in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from torch_geometric) (3.2.1)\n",
      "Requirement already satisfied: requests in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from torch_geometric) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from torch_geometric) (4.65.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from aiohttp->torch_geometric) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from aiohttp->torch_geometric) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from jinja2->torch_geometric) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from requests->torch_geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from requests->torch_geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from requests->torch_geometric) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ceragoguztuzun/miniconda3/envs/adversaGen/lib/python3.12/site-packages (from requests->torch_geometric) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install rdkit\n",
    "!pip install torch\n",
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>tg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*C*</td>\n",
       "      <td>-54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*CC(*)C</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*CC(*)CC</td>\n",
       "      <td>-24.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*CC(*)CCC</td>\n",
       "      <td>-37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*CC(*)C(C)C</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7169</th>\n",
       "      <td>*CC(*)(F)C(=O)OCCC</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7170</th>\n",
       "      <td>*CC(F)(F)C1(F)C(*)CC(O)(C(F)(F)F)C1(F)F</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7171</th>\n",
       "      <td>*CC(F)(F)C1(F)CC(CC(O)(C(F)(F)F)C(F)(F)F)CC1*</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7172</th>\n",
       "      <td>*CC(F)(F)C1(F)CC(C(O)(C(F)(F)F)C(F)(F)F)CC1*</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7173</th>\n",
       "      <td>*CC(*)(F)C(=O)OCC(Cl)(Cl)Cl</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7174 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             SMILES     tg\n",
       "0                                               *C*  -54.0\n",
       "1                                           *CC(*)C   -3.0\n",
       "2                                          *CC(*)CC  -24.1\n",
       "3                                         *CC(*)CCC  -37.0\n",
       "4                                       *CC(*)C(C)C   60.0\n",
       "...                                             ...    ...\n",
       "7169                             *CC(*)(F)C(=O)OCCC   62.0\n",
       "7170        *CC(F)(F)C1(F)C(*)CC(O)(C(F)(F)F)C1(F)F  152.0\n",
       "7171  *CC(F)(F)C1(F)CC(CC(O)(C(F)(F)F)C(F)(F)F)CC1*   98.0\n",
       "7172   *CC(F)(F)C1(F)CC(C(O)(C(F)(F)F)C(F)(F)F)CC1*  118.0\n",
       "7173                    *CC(*)(F)C(=O)OCC(Cl)(Cl)Cl  127.0\n",
       "\n",
       "[7174 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "DATA_PATH = \"./data/D1/tg_raw.csv\"\n",
    "\n",
    "data = pd.read_csv(DATA_PATH)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Draw\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from rdkit import RDLogger\n",
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GATConv, global_mean_pool, global_add_pool\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import random\n",
    "import warnings\n",
    "from matplotlib.colors import LinearSegmentedColormap, Normalize\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Add necessary imports\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Descriptors\n",
    "\n",
    "\n",
    "from torch_geometric.nn import GATv2Conv, GlobalAttention\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "from sklearn.metrics import explained_variance_score, max_error, median_absolute_error\n",
    "\n",
    "\n",
    "# Suppress RDKit warnings\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir_name = 'plots_by_c/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' function definitions '''\n",
    "# Basic data analysis\n",
    "def analyze_data(df):\n",
    "    print(\"\\nData Statistics:\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    # Plot Tg distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df['tg'], bins=30, kde=True)\n",
    "    plt.title('Distribution of Glass Transition Temperatures (Tg)')\n",
    "    plt.xlabel('Tg (°C)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.savefig(f'{plot_dir_name}tg_distribution.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Analyze SMILES complexity\n",
    "    df['smiles_length'] = df['SMILES'].apply(len)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df['smiles_length'], bins=30, kde=True)\n",
    "    plt.title('Distribution of SMILES String Lengths')\n",
    "    plt.xlabel('Length')\n",
    "    plt.ylabel('Count')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.savefig(f'{plot_dir_name}smiles_length_distribution.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Correlation between SMILES length and Tg\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x='smiles_length', y='tg', data=df, alpha=0.5)\n",
    "    plt.title('Relationship Between Molecule Complexity and Tg')\n",
    "    plt.xlabel('SMILES String Length')\n",
    "    plt.ylabel('Tg (°C)')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.savefig(f'{plot_dir_name}length_vs_tg.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actual = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            predictions.extend(output.cpu().numpy())\n",
    "            actual.extend(data.y.cpu().numpy())\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    actual = np.array(actual)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(actual, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(actual, predictions)\n",
    "    r2 = r2_score(actual, predictions)\n",
    "    \n",
    "    return {\n",
    "        'predictions': predictions,\n",
    "        'actual': actual,\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2\n",
    "    }\n",
    "\n",
    "# Early stopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        self.best_model_state = None\n",
    "    \n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_loss\n",
    "            self.best_model_state = model.state_dict().copy()\n",
    "        elif val_loss > self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = val_loss\n",
    "            self.best_model_state = model.state_dict().copy()\n",
    "            self.counter = 0\n",
    "        return self.early_stop\n",
    "\n",
    "# Training loop with visualization\n",
    "def train_and_evaluate(model, train_loader, val_loader, test_loader, optimizer, device, num_epochs=100):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_r2s = []\n",
    "    \n",
    "    # Initialize early stopping\n",
    "    early_stopping = EarlyStopping(patience=15)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Train\n",
    "        train_loss = train(model, train_loader, optimizer, device)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Validate\n",
    "        val_results = evaluate(model, val_loader, device)\n",
    "        val_loss = val_results['mse']\n",
    "        val_r2 = val_results['r2']\n",
    "        val_losses.append(val_loss)\n",
    "        val_r2s.append(val_r2)\n",
    "        \n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Print progress\n",
    "        if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, '\n",
    "                  f'Val Loss: {val_loss:.4f}, Val R²: {val_r2:.4f}')\n",
    "        \n",
    "        # Check early stopping\n",
    "        if early_stopping(val_loss, model):\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    # Load the best model\n",
    "    model.load_state_dict(early_stopping.best_model_state)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_results = evaluate(model, test_loader, device)\n",
    "    print(\"\\nTest Results:\")\n",
    "    print(f\"MSE: {test_results['mse']:.4f}\")\n",
    "    print(f\"RMSE: {test_results['rmse']:.4f}\")\n",
    "    print(f\"MAE: {test_results['mae']:.4f}\")\n",
    "    print(f\"R²: {test_results['r2']:.4f}\")\n",
    "    \n",
    "    # Plot training curves\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title('Loss Curves')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(val_r2s, label='Validation R²')\n",
    "    plt.axhline(y=test_results['r2'], color='r', linestyle='--', label='Test R²')\n",
    "    plt.title('R² Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('R² Score')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{plot_dir_name}training_curves.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot predictions vs actual\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(test_results['actual'], test_results['predictions'], alpha=0.5)\n",
    "    \n",
    "    # Add identity line\n",
    "    min_val = min(min(test_results['actual']), min(test_results['predictions']))\n",
    "    max_val = max(max(test_results['actual']), max(test_results['predictions']))\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--')\n",
    "    \n",
    "    plt.xlabel('Actual Tg (°C)')\n",
    "    plt.ylabel('Predicted Tg (°C)')\n",
    "    plt.title(f'GAT Model: Actual vs Predicted Tg (R² = {test_results[\"r2\"]:.4f})')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.savefig(f'{plot_dir_name}prediction_results.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Create residual plot\n",
    "    residuals = test_results['predictions'] - test_results['actual']\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(test_results['actual'], residuals, alpha=0.5)\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.xlabel('Actual Tg (°C)')\n",
    "    plt.ylabel('Residuals (Predicted - Actual)')\n",
    "    plt.title('Residual Plot')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.savefig(f'{plot_dir_name}residual_plot.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return model, test_results\n",
    "\n",
    "def visualize_molecule_with_attention(smiles, atom_importances, tg, idx, prediction=None, plot_dir_name=\"\"):\n",
    "    \"\"\"\n",
    "    Visualize a molecule with atom importance using a simpler approach with fewer RDKit options.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    smiles : str\n",
    "        SMILES string of the molecule\n",
    "    atom_importances : numpy array\n",
    "        Array of importance values for each atom\n",
    "    tg : float\n",
    "        Actual glass transition temperature\n",
    "    idx : str/int\n",
    "        Identifier for the saved file\n",
    "    prediction : float, optional\n",
    "        Predicted glass transition temperature\n",
    "    plot_dir_name : str, optional\n",
    "        Directory to save the plot\n",
    "    \"\"\"\n",
    "    # Convert SMILES to molecule\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        print(f\"Could not convert SMILES to molecule: {smiles}\")\n",
    "        return\n",
    "    \n",
    "    # Normalize importance values if needed\n",
    "    if len(atom_importances) > 0 and max(atom_importances) > 0:\n",
    "        norm_importances = atom_importances / max(atom_importances)\n",
    "    else:\n",
    "        norm_importances = atom_importances\n",
    "\n",
    "    # Create atom-specific highlight colors\n",
    "    highlight_atoms = []\n",
    "    highlight_colors = {}\n",
    "    \n",
    "    # Set up the colormap\n",
    "    cmap = plt.cm.coolwarm\n",
    "    \n",
    "    # Add atom properties for visualization\n",
    "    for atom_idx, importance in enumerate(norm_importances):\n",
    "        if atom_idx < mol.GetNumAtoms():\n",
    "            highlight_atoms.append(atom_idx)\n",
    "            \n",
    "            # Generate color from colormap (coolwarm: blue to red)\n",
    "            color_rgba = cmap(float(importance))\n",
    "            color_tuple = (int(color_rgba[0]*255), int(color_rgba[1]*255), int(color_rgba[2]*255))\n",
    "            highlight_colors[atom_idx] = color_tuple\n",
    "    \n",
    "    # Prepare the molecule drawing with minimal options\n",
    "    d2d = rdMolDraw2D.MolDraw2DCairo(800, 800)\n",
    "    \n",
    "    # Configure minimal drawing options\n",
    "    d2d.drawOptions().addAtomIndices = True\n",
    "    \n",
    "    # Draw the molecule with atom highlights using a simpler approach\n",
    "    rdMolDraw2D.PrepareAndDrawMolecule(\n",
    "        d2d, mol,\n",
    "        highlightAtoms=highlight_atoms,\n",
    "        highlightAtomColors=highlight_colors\n",
    "    )\n",
    "    d2d.FinishDrawing()\n",
    "    \n",
    "    # Get the PNG data and convert to PIL Image\n",
    "    png_data = d2d.GetDrawingText()\n",
    "    molecule_img = Image.open(BytesIO(png_data))\n",
    "    \n",
    "    # Create the figure with just the molecule and a colorbar\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    \n",
    "    # Display the molecule image\n",
    "    ax.imshow(molecule_img)\n",
    "    ax.set_title(f\"SMILES: {smiles}\\nTg: {tg}°C\\nPredicted Tg: {prediction:.2f}°C\", fontsize=14)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Add colorbar to show importance scale\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(0, 1))\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=ax, shrink=0.7, pad=0.05, orientation='horizontal')\n",
    "    cbar.set_label('Atom Importance', fontsize=14)\n",
    "    \n",
    "    # Add ticks at 0.0, 0.5 and 1.0 with labels\n",
    "    cbar.set_ticks([0.0, 0.5, 1.0])\n",
    "    cbar.set_ticklabels(['Low', 'Medium', 'High'])\n",
    "    \n",
    "    # Add an annotation explaining the colors\n",
    "    plt.figtext(0.5, 0.01,\n",
    "                \"Blue = Low Importance, Red = High Importance for Tg Prediction\",\n",
    "                ha=\"center\", fontsize=12,\n",
    "                bbox={\"facecolor\":\"lightgray\", \"alpha\":0.3, \"pad\":5})\n",
    "    \n",
    "    # Print the most important atoms for reference\n",
    "    top_indices = np.argsort(atom_importances)[-5:][::-1]\n",
    "    importance_text = \"Top 5 important atoms (indices): \"\n",
    "    importance_text += \", \".join([f\"{idx}({atom_importances[idx]:.3f})\" for idx in top_indices])\n",
    "    \n",
    "    # Add the importance information as an annotation on the plot\n",
    "    plt.figtext(0.5, 0.05, importance_text, ha=\"center\", fontsize=10,\n",
    "               bbox={\"facecolor\":\"white\", \"edgecolor\":\"gray\", \"alpha\":0.8, \"pad\":5})\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.07, 1, 0.97])\n",
    "    plt.savefig(f'{plot_dir_name}molecule_attention_{idx}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Also print to console for reference\n",
    "    print(f\"Top 5 important atoms for molecule {idx} (indices): {top_indices}\")\n",
    "    print(f\"Importance values: {atom_importances[top_indices]}\")\n",
    "\n",
    "# If the above approach has issues with coordinates, here's an even simpler alternative\n",
    "def visualize_molecule_with_color_overlay(smiles, atom_importances, tg, idx, prediction=None, plot_dir_name=\"\"):\n",
    "    \"\"\"\n",
    "    Visualize a molecule with atom importance by creating two overlaid images:\n",
    "    1. A standard black and white molecule with atom indices\n",
    "    2. Colored circles positioned approximately where atoms are\n",
    "    \n",
    "    Parameters are the same as previous function.\n",
    "    \"\"\"\n",
    "    # Convert SMILES to molecule\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        print(f\"Could not convert SMILES to molecule: {smiles}\")\n",
    "        return\n",
    "    \n",
    "    # Normalize importance values\n",
    "    if len(atom_importances) > 0 and max(atom_importances) > 0:\n",
    "        norm_importances = atom_importances / max(atom_importances)\n",
    "    else:\n",
    "        norm_importances = atom_importances\n",
    "    \n",
    "    # Set up the colormap\n",
    "    cmap = plt.cm.coolwarm\n",
    "    \n",
    "    # Generate a standard molecule image with atom indices\n",
    "    drawer = rdMolDraw2D.MolDraw2DCairo(800, 800)\n",
    "    drawer.drawOptions().addAtomIndices = True\n",
    "    drawer.DrawMolecule(mol)\n",
    "    drawer.FinishDrawing()\n",
    "    png_data = drawer.GetDrawingText()\n",
    "    molecule_img = Image.open(BytesIO(png_data))\n",
    "    \n",
    "    # Create a figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    \n",
    "    # Display the molecule image\n",
    "    ax.imshow(molecule_img)\n",
    "    ax.set_title(f\"SMILES: {smiles}\\nTg: {tg}°C\\nPredicted Tg: {prediction:.2f}°C\", fontsize=14)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Add colorbar\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(0, 1))\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=ax, shrink=0.7, pad=0.05, orientation='horizontal')\n",
    "    cbar.set_label('Atom Importance', fontsize=14)\n",
    "    cbar.set_ticks([0.0, 0.5, 1.0])\n",
    "    cbar.set_ticklabels(['Low', 'Medium', 'High'])\n",
    "    \n",
    "    \n",
    "    plt.figtext(0.5, 0.01, \"Blue = Low Importance, Red = High Importance for Tg Prediction\",\n",
    "                ha=\"center\", fontsize=12, \n",
    "                bbox={\"facecolor\":\"lightgray\", \"alpha\":0.3, \"pad\":5})\n",
    "    \n",
    "    plt.savefig(f'{plot_dir_name}molecule_attention_{idx}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Also print to console\n",
    "    top_indices = np.argsort(atom_importances)[-5:][::-1]\n",
    "    print(f\"Top 5 important atoms for molecule {idx} (indices): {top_indices}\")\n",
    "    print(f\"Importance values: {atom_importances[top_indices]}\")\n",
    "\n",
    "# Function to analyze model interpretation\n",
    "def analyze_model_interpretation(model, data_loader, device, num_examples=5):\n",
    "    model.eval()\n",
    "    \n",
    "    # Get a batch of examples\n",
    "    examples = []\n",
    "    predictions = []\n",
    "    for data in data_loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "            \n",
    "        for i in range(min(len(data.y), num_examples - len(examples))):\n",
    "            if len(examples) >= num_examples:\n",
    "                break\n",
    "                \n",
    "            # Extract single molecule\n",
    "            single_data = data[i].to(device)\n",
    "            \n",
    "            # Get atom importance\n",
    "            atom_importance = model.get_atom_importance(single_data)\n",
    "            \n",
    "            # Store example and prediction\n",
    "            examples.append((single_data.smiles, atom_importance, single_data.y.item()))\n",
    "            predictions.append(output[i].item())\n",
    "            \n",
    "        if len(examples) >= num_examples:\n",
    "            break\n",
    "    \n",
    "    # Visualize examples with attention weights\n",
    "    print(\"\\nVisualizing molecules with attention weights...\")\n",
    "    for i, (smiles, atom_importance, tg) in enumerate(examples):\n",
    "        #visualize_molecule_with_attention\n",
    "        visualize_molecule_with_color_overlay(smiles, atom_importance, tg, i, predictions[i])\n",
    "        \n",
    "        # Print most important atoms\n",
    "        top_indices = np.argsort(atom_importance)[-5:][::-1]\n",
    "        print(f\"\\nMolecule {i+1} (SMILES: {smiles})\")\n",
    "        print(f\"Actual Tg: {tg:.2f}°C, Predicted Tg: {predictions[i]:.2f}°C\")\n",
    "        print(f\"Top 5 important atoms (indices): {top_indices}\")\n",
    "        print(f\"Importance values: {atom_importance[top_indices]}\")\n",
    "\n",
    "# Define the GAT Model with attention\n",
    "class GATTgPredictor(torch.nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_channels=64, heads=4):\n",
    "        super(GATTgPredictor, self).__init__()\n",
    "        \n",
    "        # Graph attention layers - these will provide interpretability\n",
    "        self.conv1 = GATConv(node_features, hidden_channels, heads=heads, dropout=0.2)\n",
    "        self.conv2 = GATConv(hidden_channels*heads, hidden_channels, heads=heads, dropout=0.2)\n",
    "        self.conv3 = GATConv(hidden_channels*heads, hidden_channels, heads=1, dropout=0.2)\n",
    "        \n",
    "        # Batch normalization for stability\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels*heads)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels*heads)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        \n",
    "        # Fully connected layers for regression\n",
    "        self.fc1 = torch.nn.Linear(hidden_channels, 32)\n",
    "        self.fc2 = torch.nn.Linear(32, 1)\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        \n",
    "        # For storing attention weights\n",
    "        self.attention_weights = None\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        # First GAT layer with attention\n",
    "        x1, attention_weights1 = self.conv1(x, edge_index, return_attention_weights=True)\n",
    "        x1 = F.relu(self.bn1(x1))\n",
    "        x1 = self.dropout(x1)\n",
    "        \n",
    "        # Second GAT layer\n",
    "        x2, attention_weights2 = self.conv2(x1, edge_index, return_attention_weights=True)\n",
    "        x2 = F.relu(self.bn2(x2))\n",
    "        x2 = self.dropout(x2)\n",
    "        \n",
    "        # Third GAT layer - final layer for capturing node importance\n",
    "        x3, attention_weights3 = self.conv3(x2, edge_index, return_attention_weights=True)\n",
    "        x3 = F.relu(self.bn3(x3))\n",
    "        \n",
    "        # Store attention weights from the final layer for interpretation\n",
    "        # edge_index, attention (edge_index shape: [2, num_edges], attention shape: [num_edges, heads])\n",
    "        self.attention_weights = attention_weights3\n",
    "        \n",
    "        # Global pooling - aggregate node features for each graph\n",
    "        x = global_mean_pool(x3, batch)\n",
    "        \n",
    "        # Apply fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x.view(-1)\n",
    "    \n",
    "    # Method to get atom-level importance\n",
    "    def get_atom_importance(self, data):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            # Forward pass to get attention weights\n",
    "            _ = self(data)\n",
    "            \n",
    "            # Extract attention weights\n",
    "            edge_index, attn_weights = self.attention_weights\n",
    "            \n",
    "            # Initialize importance scores for each atom\n",
    "            num_nodes = data.x.size(0)\n",
    "            importance = torch.zeros(num_nodes, device=data.x.device)\n",
    "            \n",
    "            # Sum attention weights for each node\n",
    "            for i in range(edge_index.size(1)):\n",
    "                target_node = edge_index[1, i].item()\n",
    "                importance[target_node] += attn_weights[i].item()\n",
    "            \n",
    "            # Normalize importance scores\n",
    "            if importance.max() > 0:\n",
    "                importance = importance / importance.max()\n",
    "                \n",
    "            return importance.cpu().numpy()\n",
    "\n",
    "\n",
    "# Convert SMILES to molecular graphs\n",
    "def smiles_to_graph(smiles):\n",
    "    # Convert SMILES to RDKit molecule\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    \n",
    "    # Get atom features\n",
    "    atom_features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        # Atom features: One-hot encoding of atom type, formal charge, hybridization, aromaticity\n",
    "        atom_type_one_hot = [0] * 100  # Limit to first 100 elements\n",
    "        atom_num = atom.GetAtomicNum()\n",
    "        if atom_num < 100:\n",
    "            atom_type_one_hot[atom_num] = 1\n",
    "            \n",
    "        formal_charge = [atom.GetFormalCharge()]\n",
    "        hybridization_type = [0, 0, 0, 0, 0]  # One-hot encoding of hybridization\n",
    "        hyb_type = atom.GetHybridization()\n",
    "        if hyb_type == Chem.rdchem.HybridizationType.SP:\n",
    "            hybridization_type[0] = 1\n",
    "        elif hyb_type == Chem.rdchem.HybridizationType.SP2:\n",
    "            hybridization_type[1] = 1\n",
    "        elif hyb_type == Chem.rdchem.HybridizationType.SP3:\n",
    "            hybridization_type[2] = 1\n",
    "        elif hyb_type == Chem.rdchem.HybridizationType.SP3D:\n",
    "            hybridization_type[3] = 1\n",
    "        elif hyb_type == Chem.rdchem.HybridizationType.SP3D2:\n",
    "            hybridization_type[4] = 1\n",
    "            \n",
    "        is_aromatic = [1 if atom.GetIsAromatic() else 0]\n",
    "        degree = [atom.GetDegree()]\n",
    "        num_h = [atom.GetTotalNumHs()]\n",
    "        \n",
    "        # Combine all features\n",
    "        features = atom_type_one_hot + formal_charge + hybridization_type + is_aromatic + degree + num_h\n",
    "        atom_features.append(features)\n",
    "    \n",
    "    # Create node feature matrix (num_nodes x num_features)\n",
    "    x = torch.tensor(atom_features, dtype=torch.float)\n",
    "    \n",
    "    # Get edge indices (bonds)\n",
    "    edge_indices = []\n",
    "    edge_attr = []\n",
    "    \n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        \n",
    "        # Bond features\n",
    "        bond_type = bond.GetBondType()\n",
    "        bond_features = [0, 0, 0, 0]  # One-hot encoding of bond type\n",
    "        if bond_type == Chem.rdchem.BondType.SINGLE:\n",
    "            bond_features[0] = 1\n",
    "        elif bond_type == Chem.rdchem.BondType.DOUBLE:\n",
    "            bond_features[1] = 1\n",
    "        elif bond_type == Chem.rdchem.BondType.TRIPLE:\n",
    "            bond_features[2] = 1\n",
    "        elif bond_type == Chem.rdchem.BondType.AROMATIC:\n",
    "            bond_features[3] = 1\n",
    "            \n",
    "        is_conjugated = [1 if bond.GetIsConjugated() else 0]\n",
    "        is_in_ring = [1 if bond.IsInRing() else 0]\n",
    "        \n",
    "        # Combine all features\n",
    "        features = bond_features + is_conjugated + is_in_ring\n",
    "        \n",
    "        # Add bonds in both directions\n",
    "        edge_indices.append([i, j])\n",
    "        edge_indices.append([j, i])\n",
    "        edge_attr.append(features)\n",
    "        edge_attr.append(features)\n",
    "    \n",
    "    if len(edge_indices) == 0:  # For molecules with no bonds\n",
    "        edge_index = torch.zeros((2, 0), dtype=torch.long)\n",
    "        edge_attr = torch.zeros((0, 6), dtype=torch.float)\n",
    "    else:\n",
    "        edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, smiles=smiles)\n",
    "\n",
    "# Prepare the dataset\n",
    "def prepare_dataset(dataframe, smiles_col='SMILES', target_col='tg'):\n",
    "    data_list = []\n",
    "    valid_indices = []\n",
    "    invalid_smiles = []\n",
    "    \n",
    "    for idx, row in dataframe.iterrows():\n",
    "        smiles = row[smiles_col]\n",
    "        graph = smiles_to_graph(smiles)\n",
    "        if graph is not None:\n",
    "            # Add target value\n",
    "            graph.y = torch.tensor([row[target_col]], dtype=torch.float)\n",
    "            graph.smiles = smiles  # Store SMILES for reference\n",
    "            data_list.append(graph)\n",
    "            valid_indices.append(idx)\n",
    "        else:\n",
    "            invalid_smiles.append((idx, smiles))\n",
    "    \n",
    "    if invalid_smiles:\n",
    "        print(f\"\\nWarning: {len(invalid_smiles)} invalid SMILES strings found and skipped.\")\n",
    "        \n",
    "    return data_list, valid_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (7174, 2)\n",
      "        SMILES    tg\n",
      "0          *C* -54.0\n",
      "1      *CC(*)C  -3.0\n",
      "2     *CC(*)CC -24.1\n",
      "3    *CC(*)CCC -37.0\n",
      "4  *CC(*)C(C)C  60.0\n",
      "\n",
      "Data Statistics:\n",
      "                tg\n",
      "count  7174.000000\n",
      "mean    141.948090\n",
      "std     112.178143\n",
      "min    -139.000000\n",
      "25%      55.000000\n",
      "50%     134.000000\n",
      "75%     231.000000\n",
      "max     495.000000\n",
      "\n",
      "Valid molecules processed: 7174 out of 7174\n",
      "Training set: 4304\n",
      "Validation set: 1435\n",
      "Test set: 1435\n",
      "Using device: cpu\n",
      "Node features: 109, Edge features: 6\n",
      "\n",
      "Training the GAT model...\n",
      "Epoch 1/100, Train Loss: 32430.0928, Val Loss: 30845.1680, Val R²: -1.3288\n",
      "Epoch 10/100, Train Loss: 3775.8275, Val Loss: 4331.0649, Val R²: 0.6730\n",
      "Epoch 20/100, Train Loss: 3416.6245, Val Loss: 2999.9929, Val R²: 0.7735\n",
      "Epoch 30/100, Train Loss: 3319.8744, Val Loss: 2711.3923, Val R²: 0.7953\n",
      "Epoch 40/100, Train Loss: 3204.9772, Val Loss: 2730.4980, Val R²: 0.7938\n",
      "Epoch 50/100, Train Loss: 3076.7126, Val Loss: 2910.1516, Val R²: 0.7803\n",
      "Epoch 60/100, Train Loss: 2998.3780, Val Loss: 2861.5669, Val R²: 0.7839\n",
      "Early stopping at epoch 63\n",
      "\n",
      "Test Results:\n",
      "MSE: 2669.1233\n",
      "RMSE: 51.6636\n",
      "MAE: 38.9960\n",
      "R²: 0.7839\n",
      "\n",
      "Analyzing model interpretation with attention weights...\n",
      "\n",
      "Visualizing molecules with attention weights...\n",
      "Top 5 important atoms for molecule 0 (indices): [22 36 27 14 54]\n",
      "Importance values: [1.        1.        0.9999999 0.9999999 0.9999999]\n",
      "\n",
      "Molecule 1 (SMILES: *Oc1ccc(NC(=O)Nc2cc(NC(=O)Nc3ccc(*)c(-c4ccc(Oc5ccccc5)cc4)c3)ccc2C)cc1-c1ccc(Oc2ccccc2)cc1)\n",
      "Actual Tg: 279.00°C, Predicted Tg: 167.89°C\n",
      "Top 5 important atoms (indices): [22 36 27 14 54]\n",
      "Importance values: [1.        1.        0.9999999 0.9999999 0.9999999]\n",
      "Top 5 important atoms for molecule 1 (indices): [19 15 24 11  1]\n",
      "Importance values: [1.        1.        0.9999999 0.9999999 0.9999999]\n",
      "\n",
      "Molecule 2 (SMILES: *CCCCCCCCCCNC(=O)CCP(C)(=O)CCC(=O)N*)\n",
      "Actual Tg: 45.50°C, Predicted Tg: 34.89°C\n",
      "Top 5 important atoms (indices): [19 15 24 11  1]\n",
      "Importance values: [1.        1.        0.9999999 0.9999999 0.9999999]\n",
      "Top 5 important atoms for molecule 2 (indices): [10  9  8  7  6]\n",
      "Importance values: [1. 1. 1. 1. 1.]\n",
      "\n",
      "Molecule 3 (SMILES: *CC(*)c1ccc(F)cc1)\n",
      "Actual Tg: 95.00°C, Predicted Tg: 91.42°C\n",
      "Top 5 important atoms (indices): [10  9  8  7  6]\n",
      "Importance values: [1. 1. 1. 1. 1.]\n",
      "Top 5 important atoms for molecule 3 (indices): [38 39  9 17 14]\n",
      "Importance values: [1.        0.9999999 0.9999999 0.9999999 0.9999999]\n",
      "\n",
      "Molecule 4 (SMILES: *C(=O)c1ccc2c(c1)C(=O)N(c1ccc(C(=O)c3ccc(N4C(=O)c5ccc(*)cc5C4=O)cc3)cc1)C2=O)\n",
      "Actual Tg: 294.00°C, Predicted Tg: 275.74°C\n",
      "Top 5 important atoms (indices): [38 39  9 17 14]\n",
      "Importance values: [1.        0.9999999 0.9999999 0.9999999 0.9999999]\n",
      "Top 5 important atoms for molecule 4 (indices): [17 16  1  3  4]\n",
      "Importance values: [1. 1. 1. 1. 1.]\n",
      "\n",
      "Molecule 5 (SMILES: *N=P(*)(Oc1ccccc1)Oc1ccccc1)\n",
      "Actual Tg: -8.00°C, Predicted Tg: 11.02°C\n",
      "Top 5 important atoms (indices): [17 16  1  3  4]\n",
      "Importance values: [1. 1. 1. 1. 1.]\n",
      "\n",
      "Model training, evaluation, and interpretation complete.\n"
     ]
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# Load data\n",
    "DATA_PATH = \"./data/D1/tg_raw.csv\"\n",
    "data = pd.read_csv(DATA_PATH)\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(data.head())\n",
    "\n",
    "# Run the initial analysis\n",
    "data = analyze_data(data)\n",
    "\n",
    "# Split into train, validation, and test sets\n",
    "data_list, valid_indices = prepare_dataset(data)\n",
    "#data_list, valid_indices = prepare_dataset(data, smiles_to_graph_function=smiles_to_graph_enhanced)\n",
    "\n",
    "print(f\"\\nValid molecules processed: {len(data_list)} out of {len(data)}\")\n",
    "\n",
    "# Create train/val/test split\n",
    "train_data, test_data = train_test_split(data_list, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.25, random_state=42)  # 0.25 of 0.8 = 0.2 of total\n",
    "\n",
    "print(f\"Training set: {len(train_data)}\")\n",
    "print(f\"Validation set: {len(val_data)}\")\n",
    "print(f\"Test set: {len(test_data)}\")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64 #32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model\n",
    "if len(data_list) > 0:\n",
    "    node_features = data_list[0].x.shape[1]\n",
    "    edge_features = data_list[0].edge_attr.shape[1] if data_list[0].edge_attr.shape[0] > 0 else 0\n",
    "    print(f\"Node features: {node_features}, Edge features: {edge_features}\")\n",
    "    \n",
    "    model = GATTgPredictor(node_features, edge_features).to(device)\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "    )\n",
    "else:\n",
    "    print(\"Error: No valid molecules processed. Can't initialize model.\")\n",
    "    exit()\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nTraining the GAT model...\")\n",
    "model, test_results = train_and_evaluate(model, train_loader, val_loader, test_loader, optimizer, device)\n",
    "\n",
    "# Analyze model interpretation\n",
    "print(\"\\nAnalyzing model interpretation with attention weights...\")\n",
    "analyze_model_interpretation(model, test_loader, device, num_examples=5)\n",
    "\n",
    "\n",
    "print(\"\\nModel training, evaluation, and interpretation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adversaGen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
